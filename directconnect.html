<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Direct Connect and On-prem VM to AWS</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header>
    <h1>Direct Connect and On-prem VM to AWS</h1>
    <nav>
      <a href="index.html">← Back to Portfolio</a>
    </nav>
  </header>

<main>
  <section>
    <h2>Overview</h2>
    <p><strong>Financial Security Firm</strong></p>
    <p>Internal system migration proposal from Data Center to AWS:</p>
    <ul>
      <li>Creation of Direct Connect and VPN connection</li>
      <li>VM migration from Stratus everRun Platform to AWS</li>
    </ul>

    <h2>Existing Arrangement</h2>
    <p>
      The customer’s custom-made financial application runs on the Stratus everRun Virtualization Platform.
      Due to the physical server hardware life cycle, the customer must consider hardware replacement or
      cloud migration to reduce the physical footprint from data center colocation service while keeping
      core network devices at the data center.
    </p>
    <p>
      The Host OS for the existing Stratus everRun version runs on CentOS-based Linux. Stratus everRun is
      shifting to Ubuntu-based Linux due to CentOS’s EOL announced by Red Hat.
    </p>
    <figure>
      <figcaption>Existing hardware specification and infrastructure arrangement</figcaption>
      <img src="Existing-1.png" alt="Diagram of existing setup" /> 
    </figure>

    <h2>Approach</h2>
    <p>
      Stratus everRun Virtualization Platform provides fault-tolerant architecture and supports
      fault-tolerant workloads. The goal is to recreate a similar level of availability on AWS.
    </p>
    <figure>
      <figcaption>Proposed AWS architecture diagram</figcaption>
      <img src="Approach-1.png" alt="Migration process" /> 
      <!-- Photo will be inserted here -->
    </figure>

    <h3>Step 1: VPC and Subnet Setup</h3>

    <h3>Step 2: Routing Setup</h3>
    <p>Includes Site-to-Site VPN and Direct Connect on AWS.</p>
    <p><em>Remarks:</em> From a physical connection perspective, Direct Connect and Internet VPN connection
      from the Data Center colocation room to AWS are crucial. This process can take months due to circuit
      application, ISP coordination, cross-connect, and connectivity testing. Planning ahead is essential to
      avoid implementation delays.</p>

    <h3>Step 3: Instance Setup (EC2 and DB)</h3>
    <ul>
      <li>Windows Server EC2 instances selected for production workloads</li>
      <li>Staging instance prepared for application testing</li>
      <li>Active and Standby instances placed in separate AZs for Active-Passive failover</li>
      <li>Amazon RDS for Oracle (Managed service, License Included) with Multi-AZ deployment</li>
    </ul>

    <h3>Step 4: Route 53 Setup</h3>
    <p>
      Route 53 is selected instead of ELB health checks since instance failover is not necessary and traffic
      is low.
    </p>
    <p><em>Remarks:</em> ELB is also considered since this infrastructure setup is within one AWS region.
      ELB can provide faster failover response than Route 53. Best practice: use ELB for intra-region HA and
      Route 53 for inter-region DR.</p>

    <h3>Step 5: AWS Backup, CloudWatch, and SNS Setup</h3>
    <ul>
      <li>Snapshots taken by AWS Backup for EC2 and RDS</li>
      <li>Monitoring and alarms configured via CloudWatch and SNS</li>
    </ul>
    <figure>
      <figcaption>Monitoring and backup architecture</figcaption>
      <!-- Photo will be inserted here -->
    </figure>

    <h2>Final Architecture</h2>
    <p>
      The overall architecture connects the Financial Security Firm’s internal on-prem infrastructure to AWS.
      This hybrid arrangement integrates the customer’s HQ, branch offices, data center, and AWS.
    </p>
    <figure>
      <figcaption>Final architecture diagram</figcaption>
      <!-- Photo will be inserted here -->
    </figure>
    <p>
      Note: Other network infrastructure changes (additional hardware installation and reconfiguration work)
      are not detailed here.
    </p>

    <h2>Features</h2>
    <h3>Core Functionalities</h3>
    <ul>
      <li>Reliability & Availability
        <ul>
          <li>Failover by Route 53</li>
          <li>Multi-AZ arrangement</li>
          <li>Backup by snapshots</li>
        </ul>
      </li>
      <li>Security Enhancements
        <ul>
          <li>Secure connection via Direct Connect and Site-to-Site VPN</li>
        </ul>
      </li>
      <li>Cost Optimization
        <ul>
          <li>Use of AWS managed services to avoid over-provisioning</li>
        </ul>
      </li>
      <li>Business Value
        <ul>
          <li>Reduced hardware footprint and lower data center colocation costs</li>
        </ul>
      </li>
    </ul>

    <h2>Cost & Security Considerations</h2>
    <p>
      The cost of hardware replacement and virtualization platform upgrade versus AWS migration was a key
      decision point for the customer’s HQ management board. Security concerns over cloud migration were also
      crucial for the system department.
    </p>
    <figure>
      <figcaption>Cost and security analysis visuals</figcaption>
      <!-- Photo will be inserted here -->
    </figure>

    <h2>Hindsight</h2>
    <p>
      There were many differences between on-prem and AWS architecture arrangements. A major consideration
      was connectivity from the Data Center colocation room and direct connect edge facility to AWS.
    </p>
    <p>
      Telecom arrangements required coordination with ISPs to lay Direct Connect for more reliable AWS access.
    </p>
  </section>
</main>

  <footer>
    <p>© 2026 Your Name</p>
  </footer>
</body>
</html>